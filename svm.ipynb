{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Paths ---\n",
    "train_dir = Path(\"../Combined Dataset/train\")\n",
    "test_dir  = Path(\"../Combined Dataset/test\")\n",
    "\n",
    "# --- Image transforms ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # ensure 1-channel MRI\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# --- Load datasets ---\n",
    "train_ds = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_ds  = datasets.ImageFolder(root=test_dir,  transform=transform)\n",
    "\n",
    "# --- Dataloaders ---\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "# --- Print info ---\n",
    "print(\"Classes:\", train_ds.classes)\n",
    "print(\"Train samples:\", len(train_ds))\n",
    "print(\"Test samples:\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Extract images and labels from DataLoaders ---\n",
    "def extract_data(loader):\n",
    "    \"\"\"Convert PyTorch DataLoader to numpy arrays\"\"\"\n",
    "    images_list = []\n",
    "    labels_list = []\n",
    "    for imgs, labels in loader:\n",
    "        images_list.append(imgs.numpy())\n",
    "        labels_list.append(labels.numpy())\n",
    "    images = np.concatenate(images_list, axis=0)\n",
    "    labels = np.concatenate(labels_list, axis=0)\n",
    "    return images, labels\n",
    "\n",
    "print(\"Extracting and flattening data...\")\n",
    "X_train, y_train = extract_data(train_loader)\n",
    "X_test, y_test = extract_data(test_loader)\n",
    "\n",
    "# Flatten 128x128 images to vectors\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "print(f\"Train shape: {X_train_flat.shape}, Test shape: {X_test_flat.shape}\")\n",
    "\n",
    "# --- Create pipelines (standardization + PCA + classifier) ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NESTED CROSS-VALIDATION - Linear SVM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "pipeline_linear = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=200, random_state=42)),\n",
    "    ('svm', LinearSVC(max_iter=5000, random_state=42, dual='auto'))\n",
    "])\n",
    "\n",
    "param_grid_linear = {\n",
    "    'svm__C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Inner CV for hyperparameter tuning\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Outer CV for unbiased performance estimation\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV for inner loop\n",
    "grid_linear = GridSearchCV(\n",
    "    pipeline_linear,\n",
    "    param_grid_linear,\n",
    "    cv=inner_cv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Nested CV: outer loop\n",
    "print(\"\\nRunning outer 5-fold CV with inner 3-fold hyperparameter tuning...\")\n",
    "nested_scores_linear = cross_validate(\n",
    "    grid_linear,\n",
    "    X_train_flat, y_train,\n",
    "    cv=outer_cv,\n",
    "    scoring={'accuracy': 'accuracy', 'f1_macro': 'f1_macro'},\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"\\nLinear SVM Nested CV Results (5 outer folds):\")\n",
    "print(f\"  Test Accuracy:  {nested_scores_linear['test_accuracy'].mean():.4f} ± {nested_scores_linear['test_accuracy'].std():.4f}\")\n",
    "print(f\"  Test Macro F1:  {nested_scores_linear['test_f1_macro'].mean():.4f} ± {nested_scores_linear['test_f1_macro'].std():.4f}\")\n",
    "print(f\"  Train Accuracy: {nested_scores_linear['train_accuracy'].mean():.4f} ± {nested_scores_linear['train_accuracy'].std():.4f}\")\n",
    "print(f\"  Train Macro F1: {nested_scores_linear['train_f1_macro'].mean():.4f} ± {nested_scores_linear['train_f1_macro'].std():.4f}\")\n",
    "\n",
    "# --- RBF SVM with subsampling for inner CV only ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NESTED CROSS-VALIDATION - RBF SVM (with subsampling for speed)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# For RBF, we'll manually implement nested CV with subsampling in inner loop\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class SubsampledRBFSVM(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"RBF SVM that subsamples training data during hyperparameter search\"\"\"\n",
    "    def __init__(self, C=1.0, gamma='scale', subsample_size=2000, random_state=42):\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        self.subsample_size = subsample_size\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Always train final model on full data\n",
    "        self.model_ = SVC(kernel='rbf', C=self.C, gamma=self.gamma, random_state=self.random_state)\n",
    "        self.model_.fit(X, y)\n",
    "        self.classes_ = self.model_.classes_\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model_.predict(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return self.model_.score(X, y)\n",
    "\n",
    "pipeline_rbf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=200, random_state=42)),\n",
    "    ('svm', SubsampledRBFSVM(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_rbf = {\n",
    "    'svm__C': [1, 10, 100],\n",
    "    'svm__gamma': ['scale', 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# For RBF, use 3-fold inner and outer to save time\n",
    "inner_cv_rbf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "outer_cv_rbf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "grid_rbf = GridSearchCV(\n",
    "    pipeline_rbf,\n",
    "    param_grid_rbf,\n",
    "    cv=inner_cv_rbf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nRunning outer 3-fold CV with inner 3-fold hyperparameter tuning...\")\n",
    "nested_scores_rbf = cross_validate(\n",
    "    grid_rbf,\n",
    "    X_train_flat, y_train,\n",
    "    cv=outer_cv_rbf,\n",
    "    scoring={'accuracy': 'accuracy', 'f1_macro': 'f1_macro'},\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"\\nRBF SVM Nested CV Results (3 outer folds):\")\n",
    "print(f\"  Test Accuracy:  {nested_scores_rbf['test_accuracy'].mean():.4f} ± {nested_scores_rbf['test_accuracy'].std():.4f}\")\n",
    "print(f\"  Test Macro F1:  {nested_scores_rbf['test_f1_macro'].mean():.4f} ± {nested_scores_rbf['test_f1_macro'].std():.4f}\")\n",
    "print(f\"  Train Accuracy: {nested_scores_rbf['train_accuracy'].mean():.4f} ± {nested_scores_rbf['train_accuracy'].std():.4f}\")\n",
    "print(f\"  Train Macro F1: {nested_scores_rbf['train_f1_macro'].mean():.4f} ± {nested_scores_rbf['train_f1_macro'].std():.4f}\")\n",
    "\n",
    "# --- Compare models and select best ---\n",
    "linear_cv_f1 = nested_scores_linear['test_f1_macro'].mean()\n",
    "rbf_cv_f1 = nested_scores_rbf['test_f1_macro'].mean()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Linear SVM CV F1: {linear_cv_f1:.4f}\")\n",
    "print(f\"RBF SVM CV F1:    {rbf_cv_f1:.4f}\")\n",
    "\n",
    "# --- Train final model on FULL training set ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING FINAL MODEL ON FULL TRAINING SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if linear_cv_f1 > rbf_cv_f1:\n",
    "    print(\"\\nBest model: Linear SVM\")\n",
    "    final_pipeline = pipeline_linear\n",
    "    final_grid = param_grid_linear\n",
    "    model_name = \"Linear SVM\"\n",
    "else:\n",
    "    print(\"\\nBest model: RBF SVM\")\n",
    "    final_pipeline = pipeline_rbf\n",
    "    final_grid = param_grid_rbf\n",
    "    model_name = \"RBF SVM\"\n",
    "\n",
    "# Final hyperparameter tuning on full training set\n",
    "final_search = GridSearchCV(\n",
    "    final_pipeline,\n",
    "    final_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nFitting final model with 5-fold CV hyperparameter tuning...\")\n",
    "final_search.fit(X_train_flat, y_train)\n",
    "\n",
    "print(f\"Best hyperparameters: {final_search.best_params_}\")\n",
    "print(f\"Best CV macro F1: {final_search.best_score_:.4f}\")\n",
    "\n",
    "# --- Evaluate on held-out test set ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HELD-OUT TEST SET EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "y_pred = final_search.predict(X_test_flat)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=train_ds.classes))\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=train_ds.classes, \n",
    "            yticklabels=train_ds.classes)\n",
    "plt.title(f'Confusion Matrix - {model_name}\\nTest Accuracy: {accuracy:.4f}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Per-class confusion matrices ---\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, class_name in enumerate(train_ds.classes):\n",
    "    cm_class = confusion_matrix(y_test == idx, y_pred == idx)\n",
    "    sns.heatmap(cm_class, annot=True, fmt='d', cmap='Greens', \n",
    "                ax=axes[idx], xticklabels=['Other', class_name], \n",
    "                yticklabels=['Other', class_name])\n",
    "    axes[idx].set_title(f'{class_name}')\n",
    "    axes[idx].set_ylabel('True')\n",
    "    axes[idx].set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Summary Statistics ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nNested CV estimates (unbiased performance on unseen data):\")\n",
    "print(f\"  Linear SVM: {linear_cv_f1:.4f} ± {nested_scores_linear['test_f1_macro'].std():.4f}\")\n",
    "print(f\"  RBF SVM:    {rbf_cv_f1:.4f} ± {nested_scores_rbf['test_f1_macro'].std():.4f}\")\n",
    "print(f\"\\nFinal test set performance ({model_name}): {macro_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS3000env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
